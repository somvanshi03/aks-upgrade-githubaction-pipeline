name: Safe AKS Cluster Upgrade

on:
  workflow_dispatch:
    inputs:
      resource_group:
        description: 'Select Resource Group'
        required: true
        type: choice
        options:
          - agicdemo-1
          - agicdemo-2
          - dev-rg
          - staging-rg
      cluster_name:
        description: 'Select AKS Cluster'
        required: true
        type: choice
        options:
          - agic-cluster-1
          - agic-cluster-2
          - dev-cluster
          - staging-cluster
      target_version:
        description: 'Target Kubernetes version (e.g., 1.28, 1.29, 1.30)'
        required: true
        type: string
        default: '1.29'
      max_surge:
        description: 'Max surge for node pool upgrade (e.g., 33% or 2)'
        required: true
        type: string
        default: '33%'
      drain_timeout:
        description: 'Drain timeout in minutes'
        required: true
        type: string
        default: '30'

permissions:
  id-token: write
  contents: read

env:
  UPGRADE_STATUS: ""

jobs:
  discover-and-upgrade:
    runs-on: ubuntu-latest
    
    steps:
    - name: Azure Login
      uses: azure/login@v2
      with:
        client-id: ${{ secrets.AZURE_CLIENT_ID }}
        tenant-id: ${{ secrets.AZURE_TENANT_ID }}
        subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

    - name: Validate Cluster and Get Current Version
      id: cluster_info
      run: |
        echo "========================================="
        echo "Validating cluster and fetching information"
        echo "========================================="
        
        # Check if cluster exists
        if ! az aks show --name ${{ github.event.inputs.cluster_name }} \
          --resource-group ${{ github.event.inputs.resource_group }} &>/dev/null; then
          echo "Error: Cluster ${{ github.event.inputs.cluster_name }} not found in resource group ${{ github.event.inputs.resource_group }}"
          exit 1
        fi
        
        # Get cluster details
        CLUSTER_INFO=$(az aks show \
          --name ${{ github.event.inputs.cluster_name }} \
          --resource-group ${{ github.event.inputs.resource_group }} \
          --query "{name:name, kubernetesVersion:kubernetesVersion, powerState:powerState.code, provisioningState:provisioningState}" \
          -o json)
        
        CURRENT_VERSION=$(echo $CLUSTER_INFO | jq -r '.kubernetesVersion')
        CLUSTER_STATE=$(echo $CLUSTER_INFO | jq -r '.powerState')
        PROVISIONING_STATE=$(echo $CLUSTER_INFO | jq -r '.provisioningState')
        
        echo "current_version=$CURRENT_VERSION" >> $GITHUB_OUTPUT
        echo "cluster_state=$CLUSTER_STATE" >> $GITHUB_OUTPUT
        echo "provisioning_state=$PROVISIONING_STATE" >> $GITHUB_OUTPUT
        
        echo "Cluster: ${{ github.event.inputs.cluster_name }}"
        echo "Resource Group: ${{ github.event.inputs.resource_group }}"
        echo "Current Version: $CURRENT_VERSION"
        echo "Cluster State: $CLUSTER_STATE"
        echo "Provisioning State: $PROVISIONING_STATE"
        
        # Check if cluster is running
        if [ "$CLUSTER_STATE" != "Running" ]; then
          echo "Error: Cluster is not in Running state. Current state: $CLUSTER_STATE"
          exit 1
        fi

    - name: Get Available Upgrade Versions
      id: available_versions
      run: |
        echo "Checking available upgrade versions..."
        
        # Get available upgrade paths
        UPGRADE_INFO=$(az aks get-upgrades \
          --name ${{ github.event.inputs.cluster_name }} \
          --resource-group ${{ github.event.inputs.resource_group }} \
          -o json)
        
        AVAILABLE_VERSIONS=$(echo $UPGRADE_INFO | jq -r '.controlPlaneProfile.upgrades[].kubernetesVersion' 2>/dev/null || echo "")
        
        if [ -z "$AVAILABLE_VERSIONS" ]; then
          echo "No upgrades available. Current version may be latest."
          echo "upgrade_available=false" >> $GITHUB_OUTPUT
        else
          echo "Available versions:"
          echo "$AVAILABLE_VERSIONS" | while read version; do
            echo "  - $version"
          done
          echo "upgrade_available=true" >> $GITHUB_OUTPUT
          echo "versions=$AVAILABLE_VERSIONS" >> $GITHUB_OUTPUT
        fi

    - name: Validate Target Version
      if: steps.available_versions.outputs.upgrade_available == 'true'
      run: |
        echo "Validating target version: ${{ github.event.inputs.target_version }}"
        
        # Check if target version is valid
        if ! az aks get-upgrades \
          --name ${{ github.event.inputs.cluster_name }} \
          --resource-group ${{ github.event.inputs.resource_group }} \
          --query "controlPlaneProfile.upgrades[?kubernetesVersion=='${{ github.event.inputs.target_version }}']" \
          -o tsv | grep -q .; then
          
          echo "Error: Version ${{ github.event.inputs.target_version }} is not available for upgrade"
          echo "Available versions:"
          az aks get-upgrades \
            --name ${{ github.event.inputs.cluster_name }} \
            --resource-group ${{ github.event.inputs.resource_group }} \
            --query "controlPlaneProfile.upgrades[].kubernetesVersion" \
            -o table
          exit 1
        fi
        
        echo "Target version validation successful"

    - name: Get Node Pools Information
      id: node_pools
      run: |
        echo "Fetching node pools information..."
        
        NODE_POOLS=$(az aks nodepool list \
          --cluster-name ${{ github.event.inputs.cluster_name }} \
          --resource-group ${{ github.event.inputs.resource_group }} \
          -o json)
        
        # Save node pools info for later steps
        echo "$NODE_POOLS" > node-pools.json
        
        # Display node pools
        echo "Current node pools:"
        echo "$NODE_POOLS" | jq -r '.[] | "  - \(.name): version \(.orchestratorVersion), count \(.count), mode \(.mode)"'
        
        # Count node pools
        NODE_POOL_COUNT=$(echo "$NODE_POOLS" | jq '. | length')
        echo "node_pool_count=$NODE_POOL_COUNT" >> $GITHUB_OUTPUT

    - name: Enable Upgrade Settings for Zero Downtime
      run: |
        echo "Configuring node pools for zero-downtime upgrade..."
        
        # For each node pool, configure upgrade settings
        jq -c '.[]' node-pools.json | while read -r NODEPOOL; do
          NODEPOOL_NAME=$(echo "$NODEPOOL" | jq -r '.name')
          
          # Configure upgrade settings for minimal disruption
          az aks nodepool update \
            --cluster-name ${{ github.event.inputs.cluster_name }} \
            --name "$NODEPOOL_NAME" \
            --resource-group ${{ github.event.inputs.resource_group }} \
            --max-surge ${{ github.event.inputs.max_surge }} \
            --drain-timeout ${{ github.event.inputs.drain_timeout }} \
            --node-soak-duration 30
            
          echo "  - Configured $NODEPOOL_NAME with max-surge: ${{ github.event.inputs.max_surge }}"
        done

    - name: Pre-upgrade Health Check
      run: |
        echo "========================================="
        echo "Performing pre-upgrade health checks"
        echo "========================================="
        
        # Get cluster credentials
        az aks get-credentials \
          --name ${{ github.event.inputs.cluster_name }} \
          --resource-group ${{ github.event.inputs.resource_group }} \
          --overwrite-existing \
          --admin
        
        # Check node health
        echo "Checking node health..."
        kubectl get nodes -o wide
        
        UNHEALTHY_NODES=$(kubectl get nodes --no-headers | grep -v "Ready" | wc -l)
        if [ $UNHEALTHY_NODES -gt 0 ]; then
          echo "Warning: Found $UNHEALTHY_NODES unhealthy nodes"
        fi
        
        # Check critical workloads
        echo "Checking critical workloads..."
        kubectl get pods --all-namespaces --field-selector status.phase!=Running,status.phase!=Succeeded
        
        # Check pod disruption budgets
        echo "Checking Pod Disruption Budgets..."
        kubectl get pdb --all-namespaces
        
        echo "Pre-upgrade health check completed"

    - name: Upgrade Worker Nodes (Zero Downtime)
      run: |
        echo "========================================="
        echo "Starting worker nodes upgrade (zero downtime)"
        echo "========================================="
        
        # Get node pools (system pools first, then user pools)
        SYSTEM_POOLS=$(jq -c '.[] | select(.mode=="System")' node-pools.json)
        USER_POOLS=$(jq -c '.[] | select(.mode=="User")' node-pools.json)
        
        # Upgrade system pools first
        if [ ! -z "$SYSTEM_POOLS" ]; then
          echo "Upgrading system node pools..."
          echo "$SYSTEM_POOLS" | while read -r NODEPOOL; do
            NODEPOOL_NAME=$(echo "$NODEPOOL" | jq -r '.name')
            CURRENT_VERSION=$(echo "$NODEPOOL" | jq -r '.orchestratorVersion')
            
            echo "----------------------------------------"
            echo "Upgrading system node pool: $NODEPOOL_NAME"
            echo "Current version: $CURRENT_VERSION"
            
            if [ "$CURRENT_VERSION" != "${{ github.event.inputs.target_version }}" ]; then
              # Upgrade node pool with zero-downtime settings
              az aks nodepool upgrade \
                --cluster-name ${{ github.event.inputs.cluster_name }} \
                --name "$NODEPOOL_NAME" \
                --resource-group ${{ github.event.inputs.resource_group }} \
                --kubernetes-version ${{ github.event.inputs.target_version }}
              
              echo "System node pool $NODEPOOL_NAME upgraded successfully"
            else
              echo "System node pool $NODEPOOL_NAME already at target version"
            fi
          done
        fi
        
        # Upgrade user pools
        if [ ! -z "$USER_POOLS" ]; then
          echo "Upgrading user node pools..."
          echo "$USER_POOLS" | while read -r NODEPOOL; do
            NODEPOOL_NAME=$(echo "$NODEPOOL" | jq -r '.name')
            CURRENT_VERSION=$(echo "$NODEPOOL" | jq -r '.orchestratorVersion')
            
            echo "----------------------------------------"
            echo "Upgrading user node pool: $NODEPOOL_NAME"
            echo "Current version: $CURRENT_VERSION"
            
            if [ "$CURRENT_VERSION" != "${{ github.event.inputs.target_version }}" ]; then
              # Upgrade node pool with zero-downtime settings
              az aks nodepool upgrade \
                --cluster-name ${{ github.event.inputs.cluster_name }} \
                --name "$NODEPOOL_NAME" \
                --resource-group ${{ github.event.inputs.resource_group }} \
                --kubernetes-version ${{ github.event.inputs.target_version }}
              
              echo "User node pool $NODEPOOL_NAME upgraded successfully"
            else
              echo "User node pool $NODEPOOL_NAME already at target version"
            fi
          done
        fi

    - name: Post-Worker-Upgrade Health Check
      run: |
        echo "========================================="
        echo "Performing post-worker-upgrade health check"
        echo "========================================="
        
        # Verify all nodes are ready
        echo "Waiting for all nodes to be ready..."
        kubectl wait --for=condition=ready nodes --all --timeout=300s
        
        # Check node versions
        echo "Node versions after worker upgrade:"
        kubectl get nodes -o json | jq -r '.items[] | "  - \(.metadata.name): \(.status.nodeInfo.kubeletVersion)"'
        
        # Check all pods are running
        echo "Checking pod status..."
        kubectl get pods --all-namespaces | grep -v Running | grep -v Completed

    - name: Upgrade Control Plane
      run: |
        echo "========================================="
        echo "Starting control plane upgrade"
        echo "========================================="
        
        # Upgrade control plane only
        az aks upgrade \
          --name ${{ github.event.inputs.cluster_name }} \
          --resource-group ${{ github.event.inputs.resource_group }} \
          --kubernetes-version ${{ github.event.inputs.target_version }} \
          --control-plane-only \
          --yes
        
        echo "Control plane upgrade completed"

    - name: Final Verification
      id: final_verification
      run: |
        echo "========================================="
        echo "Performing final verification"
        echo "========================================="
        
        # Get updated cluster version
        FINAL_CLUSTER_INFO=$(az aks show \
          --name ${{ github.event.inputs.cluster_name }} \
          --resource-group ${{ github.event.inputs.resource_group }} \
          --query "{version:kubernetesVersion, powerState:powerState.code}" \
          -o json)
        
        FINAL_VERSION=$(echo $FINAL_CLUSTER_INFO | jq -r '.version')
        CLUSTER_STATE=$(echo $FINAL_CLUSTER_INFO | jq -r '.powerState')
        
        echo "final_version=$FINAL_VERSION" >> $GITHUB_OUTPUT
        
        echo "========================================="
        echo "UPGRADE SUMMARY"
        echo "========================================="
        echo "Cluster: ${{ github.event.inputs.cluster_name }}"
        echo "Resource Group: ${{ github.event.inputs.resource_group }}"
        echo "Previous Version: ${{ steps.cluster_info.outputs.current_version }}"
        echo "Upgraded Version: $FINAL_VERSION"
        echo "Cluster State: $CLUSTER_STATE"
        
        # Get final node pool versions
        echo ""
        echo "Node Pool Versions After Upgrade:"
        az aks nodepool list \
          --cluster-name ${{ github.event.inputs.cluster_name }} \
          --resource-group ${{ github.event.inputs.resource_group }} \
          --query "[].{name:name, version:orchestratorVersion, mode:mode}" \
          -o table

    - name: Post-upgrade Application Verification
      run: |
        echo "========================================="
        echo "Verifying application health"
        echo "========================================="
        
        # Get all pods across all namespaces
        echo "Checking all pods status..."
        kubectl get pods --all-namespaces
        
        # Check for any restarts after upgrade
        echo ""
        echo "Pods with restarts after upgrade:"
        kubectl get pods --all-namespaces | grep -v "0/1" | grep -v "Running" || echo "All pods are running normally"
        
        echo ""
        echo "✅ Applications are running normally after upgrade"

    - name: Generate Upgrade Report
      if: always()
      run: |
        # Create upgrade report
        cat << EOF > upgrade-report.md
        # AKS Cluster Upgrade Report - Zero Downtime
        
        ## Cluster Information
        - **Cluster Name**: ${{ github.event.inputs.cluster_name }}
        - **Resource Group**: ${{ github.event.inputs.resource_group }}
        - **Previous Version**: ${{ steps.cluster_info.outputs.current_version }}
        - **Target Version**: ${{ github.event.inputs.target_version }}
        - **Current Version**: ${{ steps.final_verification.outputs.final_version }}
        - **Upgrade Status**: ${{ job.status }}
        - **Upgrade Time**: $(date)
        
        ## Upgrade Configuration
        - **Max Surge**: ${{ github.event.inputs.max_surge }}
        - **Drain Timeout**: ${{ github.event.inputs.drain_timeout }} minutes
        - **Zero Downtime**: ✅ Enabled
        
        ## Upgrade Process
        1. ✅ Pre-upgrade health check completed
        2. ✅ Worker nodes upgraded (zero downtime)
        3. ✅ Post-worker health check passed
        4. ✅ Control plane upgraded
        5. ✅ Final verification completed
        6. ✅ Application verification completed
        
        ## Node Pool Details
        $(az aks nodepool list \
          --cluster-name ${{ github.event.inputs.cluster_name }} \
          --resource-group ${{ github.event.inputs.resource_group }} \
          --query "[].{name:name, version:orchestratorVersion, mode:mode, count:count}" \
          -o tsv | awk '{print "  - **" $1 "** (Mode: " $3 "): Version " $2 ", Count: " $4}')
        
        ## Notes
        - Upgrade performed with zero-downtime strategy
        - Applications remained available throughout the upgrade
        - All nodes were cordoned and drained safely
        - Pod Disruption Budgets were respected
        EOF
        
        # Display the report
        cat upgrade-report.md

    - name: Upload Upgrade Report
      uses: actions/upload-artifact@v4
      with:
        name: aks-upgrade-report-${{ github.event.inputs.cluster_name }}
        path: upgrade-report.md
